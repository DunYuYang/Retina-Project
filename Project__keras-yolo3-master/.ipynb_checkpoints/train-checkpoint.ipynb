{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv3 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package\n",
    "- numpy = 1.15.2\n",
    "- opencv-python =3.4.3\n",
    "- tqdm = 4.27.0\n",
    "- matplotlib = 2.2.3\n",
    "- tensorflow = 1.10.0\n",
    "- keras = 2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 架構流程 \n",
    "- 1. 動所需參數train_annot_folde,train_image_folder,cache_name,labels,saved_weights_name\n",
    "- 2. 執行訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# https://github.com/experiencor/keras-yolo3\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from voc import parse_voc_annotation\n",
    "from yolo import create_yolov3_model, dummy_loss\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize, evaluate, makedirs\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from callbacks import CustomModelCheckpoint, CustomTensorBoard\n",
    "from utils.multi_gpu_model import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_instances(\n",
    "    train_annot_folder,\n",
    "    train_image_folder,\n",
    "    train_cache,\n",
    "    valid_annot_folder,\n",
    "    valid_image_folder,\n",
    "    valid_cache,\n",
    "    labels,\n",
    "):\n",
    "    # parse annotations of the training set\n",
    "    train_ints, train_labels = parse_voc_annotation(train_annot_folder, train_image_folder, train_cache, labels)\n",
    "    # parse annotations of the validation set, if any, otherwise split the training set\n",
    "    if os.path.exists(valid_annot_folder):\n",
    "        valid_ints, valid_labels = parse_voc_annotation(valid_annot_folder, valid_image_folder, valid_cache, labels)\n",
    "    else:\n",
    "        print(\"valid_annot_folder not exists. Spliting the trainining set.\")\n",
    "\n",
    "        train_valid_split = int(0.8*len(train_ints))\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(train_ints)\n",
    "        np.random.seed()\n",
    "\n",
    "        valid_ints = train_ints[train_valid_split:]\n",
    "        train_ints = train_ints[:train_valid_split]\n",
    "\n",
    "    # compare the seen labels with the given labels\n",
    "    if len(labels) > 0:\n",
    "        overlap_labels = set(labels).intersection(set(train_labels.keys()))\n",
    "\n",
    "        print('Seen labels: \\t'  + str(train_labels) + '\\n')\n",
    "        print('Given labels: \\t' + str(labels))\n",
    "\n",
    "        # return None, None, None if some given label is not in the dataset\n",
    "        if len(overlap_labels) < len(labels):\n",
    "            print('Some labels have no annotations! Please revise the list of labels')\n",
    "            return None, None, None\n",
    "    else:\n",
    "        print('No labels are provided. Train on all seen labels.')\n",
    "        print(train_labels)\n",
    "        labels = train_labels.keys()\n",
    "\n",
    "    max_box_per_image = max([len(inst['object']) for inst in (train_ints + valid_ints)])\n",
    "\n",
    "    return train_ints, valid_ints, sorted(labels), max_box_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(saved_weights_name, model_to_save):\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor     = 'loss', \n",
    "        min_delta   = 0.01, \n",
    "        patience    = 5, \n",
    "        mode        = 'min', \n",
    "        verbose     = 1\n",
    "    )\n",
    "    checkpoint = CustomModelCheckpoint(\n",
    "        model_to_save   = model_to_save,\n",
    "        filepath        = saved_weights_name,# + '{epoch:02d}.h5', \n",
    "        monitor         = 'loss', \n",
    "        verbose         = 1, \n",
    "        save_best_only  = True, \n",
    "        mode            = 'min', \n",
    "        period          = 1\n",
    "    )\n",
    "    reduce_on_plateau = ReduceLROnPlateau(\n",
    "        monitor  = 'loss',\n",
    "        factor   = 0.1,\n",
    "        patience = 2,\n",
    "        verbose  = 1,\n",
    "        mode     = 'min',\n",
    "        epsilon  = 0.01,\n",
    "        cooldown = 0,\n",
    "        min_lr   = 0\n",
    "    )    \n",
    "    return [early_stop, checkpoint, reduce_on_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    nb_class, \n",
    "    anchors, \n",
    "    max_box_per_image, \n",
    "    max_grid, batch_size, \n",
    "    warmup_batches, \n",
    "    ignore_thresh,  \n",
    "    saved_weights_name, \n",
    "    lr,\n",
    "    grid_scales,\n",
    "    obj_scale=5,\n",
    "    noobj_scale=1,\n",
    "    xywh_scale=1,\n",
    "    class_scale=1  \n",
    "):\n",
    "    train_model, infer_model = create_yolov3_model(\n",
    "        nb_class            = nb_class, \n",
    "        anchors             = anchors, \n",
    "        max_box_per_image   = max_box_per_image, \n",
    "        max_grid            = max_grid, \n",
    "        batch_size          = batch_size, \n",
    "        warmup_batches      = warmup_batches,\n",
    "        ignore_thresh       = ignore_thresh,\n",
    "        grid_scales         = grid_scales,\n",
    "        obj_scale           = obj_scale,\n",
    "        noobj_scale         = noobj_scale,\n",
    "        xywh_scale          = xywh_scale,\n",
    "        class_scale         = class_scale\n",
    "    )  \n",
    "\n",
    "    # load the pretrained weight if exists, otherwise load the backend weight only\n",
    "    if os.path.exists(saved_weights_name): \n",
    "        print(\"\\nLoading pretrained weights.\\n\")\n",
    "        train_model.load_weights(saved_weights_name)\n",
    "    else:\n",
    "        train_model.load_weights(\"backend.h5\", by_name=True)          \n",
    "\n",
    "    optimizer = Adam(lr=lr, clipnorm=0.001)\n",
    "    train_model.compile(loss=dummy_loss, optimizer=optimizer)             \n",
    "\n",
    "    return train_model, infer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參數設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#更改訓練資料夾路徑，以及cache_name\n",
    "# Parse the annotations\n",
    "\n",
    "min_input_size = 288\n",
    "max_input_size = 448\n",
    "# Create the generators \n",
    "anchors = [55,69, 75,234, 133,240, 136,129, 142,363, 203,290, 228,184, 285,359, 341,260]\n",
    "labels = ['CNV', 'DME', 'DRUSEN']\n",
    "\n",
    "# 可在這更改batch_size\n",
    "batch_size = 2\n",
    "\n",
    "train_annot_folder = './retina/annots/'\n",
    "train_image_folder = './retina/images/'\n",
    "cache_name = 'retina.pkl'\n",
    "\n",
    "#更改儲存model名稱\n",
    "# Create the model \n",
    "saved_weights_name = 'retina.h5'\n",
    "\n",
    "warmup_epochs = 3\n",
    "nb_epochs = 30\n",
    "train_times = 8\n",
    "ignore_thresh = 0.5\n",
    "learning_rate = 1e-4\n",
    "grid_scales = [1,1,1]\n",
    "obj_scale = 5\n",
    "\n",
    "valid_annot_folder = ''\n",
    "valid_image_folder = ''\n",
    "valid_cache_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_annot_folder not exists. Spliting the trainining set.\n",
      "Seen labels: \t{'CNV': 252, 'DME': 146, 'DRUSEN': 183}\n",
      "\n",
      "Given labels: \t['CNV', 'DME', 'DRUSEN']\n",
      "\n",
      "Training on: \t['CNV', 'DME', 'DRUSEN']\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/keras-yolo3-master/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/jovyan/keras-yolo3-master/yolo.py:149: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jovyan/keras-yolo3-master/yolo.py:179: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.compat.v1.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "\n",
      "Loading pretrained weights.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      " - 195s - loss: 4.4616 - yolo_layer_1_loss: 0.0257 - yolo_layer_2_loss: 0.9739 - yolo_layer_3_loss: 3.4620\n",
      "\n",
      "Epoch 00001: loss improved from inf to 4.46160, saving model to retina.h5\n",
      "resizing:  320 320\n",
      "Epoch 2/10\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      " - 171s - loss: 4.2860 - yolo_layer_1_loss: 0.0232 - yolo_layer_2_loss: 0.7912 - yolo_layer_3_loss: 3.4716\n",
      "\n",
      "Epoch 00002: loss improved from 4.46160 to 4.28598, saving model to retina.h5\n",
      "Epoch 3/10\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      " - 178s - loss: 4.4597 - yolo_layer_1_loss: 0.0442 - yolo_layer_2_loss: 1.1502 - yolo_layer_3_loss: 3.2653\n",
      "\n",
      "Epoch 00003: loss did not improve from 4.28598\n",
      "Epoch 4/10\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      " - 179s - loss: 4.2399 - yolo_layer_1_loss: 0.0251 - yolo_layer_2_loss: 1.0445 - yolo_layer_3_loss: 3.1703\n",
      "\n",
      "Epoch 00004: loss improved from 4.28598 to 4.23994, saving model to retina.h5\n",
      "Epoch 5/10\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      " - 173s - loss: 4.0864 - yolo_layer_1_loss: 0.0099 - yolo_layer_2_loss: 0.9633 - yolo_layer_3_loss: 3.1132\n",
      "\n",
      "Epoch 00005: loss improved from 4.23994 to 4.08644, saving model to retina.h5\n",
      "Epoch 6/10\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      " - 173s - loss: 4.0143 - yolo_layer_1_loss: 0.0100 - yolo_layer_2_loss: 0.9793 - yolo_layer_3_loss: 3.0250\n",
      "\n",
      "Epoch 00006: loss improved from 4.08644 to 4.01432, saving model to retina.h5\n",
      "Epoch 7/10\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      " - 170s - loss: 3.7370 - yolo_layer_1_loss: 0.0158 - yolo_layer_2_loss: 0.8408 - yolo_layer_3_loss: 2.8805\n",
      "\n",
      "Epoch 00007: loss improved from 4.01432 to 3.73705, saving model to retina.h5\n",
      "Epoch 8/10\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      " - 170s - loss: 3.5882 - yolo_layer_1_loss: 0.0162 - yolo_layer_2_loss: 0.7804 - yolo_layer_3_loss: 2.7916\n",
      "\n",
      "Epoch 00008: loss improved from 3.73705 to 3.58819, saving model to retina.h5\n",
      "Epoch 9/10\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      " - 171s - loss: 3.6504 - yolo_layer_1_loss: 0.0242 - yolo_layer_2_loss: 0.8697 - yolo_layer_3_loss: 2.7566\n",
      "\n",
      "Epoch 00009: loss did not improve from 3.58819\n",
      "resizing:  416 416\n",
      "Epoch 10/10\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  320 320\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  384 384\n",
      "resizing:  288 288\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  416 416\n",
      "resizing:  352 352\n",
      "resizing:  384 384\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  320 320\n",
      "resizing:  288 288\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  448 448\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  352 352\n",
      "resizing:  448 448\n",
      "resizing:  288 288\n",
      "resizing:  384 384\n",
      "resizing:  320 320\n",
      "resizing:  416 416\n",
      "resizing:  288 288\n",
      "resizing:  320 320\n",
      "resizing:  352 352\n",
      "resizing:  416 416\n",
      "resizing:  384 384\n",
      " - 177s - loss: 3.8179 - yolo_layer_1_loss: 0.0046 - yolo_layer_2_loss: 1.1703 - yolo_layer_3_loss: 2.6429\n",
      "\n",
      "Epoch 00010: loss did not improve from 3.58819\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f50d9219cf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ints, valid_ints, labels, max_box_per_image = create_training_instances(\n",
    "    train_annot_folder,\n",
    "    train_image_folder,\n",
    "    cache_name,\n",
    "    valid_annot_folder,\n",
    "    valid_image_folder,\n",
    "    valid_cache_name,\n",
    "    labels\n",
    ")\n",
    "print('\\nTraining on: \\t' + str(labels) + '\\n')\n",
    "\n",
    "\n",
    "train_generator = BatchGenerator(\n",
    "    instances           = train_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size,\n",
    "    min_net_size        = min_input_size,\n",
    "    max_net_size        = max_input_size,   \n",
    "    shuffle             = True, \n",
    "    jitter              = 0.3, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n",
    "valid_generator = BatchGenerator(\n",
    "    instances           = valid_ints, \n",
    "    anchors             = anchors,   \n",
    "    labels              = labels,        \n",
    "    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = max_box_per_image,\n",
    "    batch_size          = batch_size,\n",
    "    min_net_size        = min_input_size,\n",
    "    max_net_size        = max_input_size,   \n",
    "    shuffle             = True, \n",
    "    jitter              = 0.0, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n",
    "\n",
    "if os.path.exists(saved_weights_name): \n",
    "    warmup_epochs = 0\n",
    "warmup_batches = warmup_epochs * (train_times*len(train_generator))\n",
    "\n",
    "train_model, infer_model = create_model(\n",
    "    nb_class            = len(labels), \n",
    "    anchors             = anchors, \n",
    "    max_box_per_image   = max_box_per_image, \n",
    "    max_grid            = [max_input_size, max_input_size], \n",
    "    batch_size          = batch_size, \n",
    "    warmup_batches      = warmup_batches,\n",
    "    ignore_thresh       = 0.5,\n",
    "    saved_weights_name  = saved_weights_name,\n",
    "    lr                  = 1e-4,\n",
    "    grid_scales         = [1,1,1],\n",
    "\n",
    ")\n",
    "\n",
    "# Start training\n",
    "callbacks = create_callbacks(saved_weights_name, infer_model)\n",
    "\n",
    "train_model.fit_generator(\n",
    "    generator        = train_generator, \n",
    "    steps_per_epoch  = len(train_generator) * train_times, \n",
    "    epochs           = nb_epochs + warmup_epochs, \n",
    "    verbose          = 2,\n",
    "    callbacks        = callbacks, \n",
    "    workers          = 4,\n",
    "    max_queue_size   = 8\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNV: 0.8286\n",
      "DME: 0.7991\n",
      "DRUSEN: 0.7325\n",
      "mAP: 0.7867\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from voc import parse_voc_annotation\n",
    "from yolo import create_yolov3_model\n",
    "from generator import BatchGenerator\n",
    "from utils.utils import normalize, evaluate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "config_path = './config.json'\n",
    "\n",
    "with open(config_path) as config_buffer:    \n",
    "    config = json.loads(config_buffer.read())\n",
    "\n",
    "###############################\n",
    "#   Create the validation generator\n",
    "###############################  \n",
    "valid_ints, labels = parse_voc_annotation(\n",
    "    config['valid']['valid_annot_folder'], \n",
    "    config['valid']['valid_image_folder'], \n",
    "    config['valid']['cache_name'],\n",
    "    config['model']['labels']\n",
    ")\n",
    "\n",
    "labels = labels.keys() if len(config['model']['labels']) == 0 else config['model']['labels']\n",
    "labels = sorted(labels)\n",
    "\n",
    "valid_generator = BatchGenerator(\n",
    "    instances           = valid_ints, \n",
    "    anchors             = config['model']['anchors'],   \n",
    "    labels              = labels,        \n",
    "    downsample          = 32, # ratio between network input's size and network output's size, 32 for YOLOv3\n",
    "    max_box_per_image   = 0,\n",
    "    batch_size          = config['train']['batch_size'],\n",
    "    min_net_size        = config['model']['min_input_size'],\n",
    "    max_net_size        = config['model']['max_input_size'],   \n",
    "    shuffle             = True, \n",
    "    jitter              = 0.0, \n",
    "    norm                = normalize\n",
    ")\n",
    "\n",
    "###############################\n",
    "#   Load the model and do evaluation\n",
    "###############################\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = config['train']['gpus']\n",
    "\n",
    "infer_model = load_model(config['train']['saved_weights_name'])\n",
    "\n",
    "# compute mAP for all the classes\n",
    "average_precisions = evaluate(infer_model, valid_generator)\n",
    "\n",
    "# print the score\n",
    "for label, average_precision in average_precisions.items():\n",
    "    print(labels[label] + ': {:.4f}'.format(average_precision))\n",
    "print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
