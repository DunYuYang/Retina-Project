{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov3 predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package\n",
    "- numpy = 1.15.2\n",
    "- opencv-python =3.4.3\n",
    "- tqdm = 4.27.0\n",
    "- matplotlib = 2.2.3\n",
    "- tensorflow = 1.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import 所需檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "from utils.utils import get_yolo_boxes, makedirs\n",
    "from utils.bbox import draw_boxes\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.colors import get_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#更改檔案input\n",
    "input_path   = 'retina.mp4'\n",
    "labels = ['CNV', 'DME', 'DRUSEN']\n",
    "# Load the model\n",
    "infer_model = load_model('retina.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "output_path  = 'output/'\n",
    "makedirs(output_path)\n",
    "\n",
    "# Set some parameter\n",
    "net_h, net_w = 416, 416 # a multiple of 32, the smaller the faster\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [55,69, 75,234, 133,240, 136,129, 142,363, 203,290, 228,184, 285,359, 341,260]\n",
    "\n",
    "\n",
    "# Predict bounding boxes \n",
    "if input_path[-4:] == '.mp4': # do detection on a video  \n",
    "    video_out = output_path + input_path.split('/')[-1]\n",
    "    video_reader = cv2.VideoCapture(input_path)\n",
    "\n",
    "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "    video_writer = cv2.VideoWriter(video_out,\n",
    "                           cv2.VideoWriter_fourcc(*'MPEG'), \n",
    "                           24.0, \n",
    "                           (frame_w, frame_h))\n",
    "    # the main loop\n",
    "    batch_size  = 1\n",
    "    images      = []\n",
    "    start_point = 0 #%\n",
    "    show_window = False\n",
    "    status = 0\n",
    "    mem = []\n",
    "    for i in tqdm(range(nb_frames)):\n",
    "        _, image = video_reader.read()\n",
    "        if image is None:\n",
    "            continue\n",
    "        if (float(i+1)/nb_frames) > start_point/100.:\n",
    "            images += [image]\n",
    "\n",
    "            if (i%batch_size == 0) or (i == (nb_frames-1) and len(images) > 0):\n",
    "                # predict the bounding boxes\n",
    "                batch_boxes = get_yolo_boxes(infer_model, images, net_h, net_w, anchors, obj_thresh, nms_thresh)\n",
    "\n",
    "                for i in range(len(images)):\n",
    "                    # draw bounding boxes on the image using labels\n",
    "                    draw_boxes(images[i], batch_boxes[i], labels, obj_thresh)   \n",
    "\n",
    "                    # show the video with detection bounding boxes          \n",
    "                    if show_window: cv2.imshow('video with bboxes', images[i])  \n",
    "\n",
    "                    # write result to the output video\n",
    "                    video_writer.write(images[i]) \n",
    "                images = []\n",
    "            if show_window and cv2.waitKey(1) == 27: break  # esc to quit\n",
    "\n",
    "    if show_window: cv2.destroyAllWindows()\n",
    "    video_reader.release()\n",
    "    video_writer.release()       \n",
    "else: # do detection on an image or a set of images\n",
    "    image_paths = []\n",
    "\n",
    "    if os.path.isdir(input_path): \n",
    "        for inp_file in os.listdir(input_path):\n",
    "            image_paths += [input_path + inp_file]\n",
    "    else:\n",
    "        image_paths += [input_path]\n",
    "\n",
    "    image_paths = [inp_file for inp_file in image_paths if (inp_file[-4:] in ['.jpg', '.png', 'JPEG'])]\n",
    "\n",
    "    # the main loop\n",
    "    for image_path in image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        print(image_path)\n",
    "\n",
    "        # predict the bounding boxes\n",
    "        boxes = get_yolo_boxes(infer_model, [image], net_h, net_w, anchors, obj_thresh, nms_thresh)[0]\n",
    "\n",
    "        # draw bounding boxes on the image using labels\n",
    "        draw_boxes(image, boxes, labels, obj_thresh) \n",
    "\n",
    "        # write the image with bounding boxes to file\n",
    "        output_img_path = output_path + image_path.split('/')[-1]\n",
    "        cv2.imwrite(output_img_path, np.uint8(image))\n",
    "        img = cv2.imread(output_img_path)[:,:,::-1]\n",
    "        plt.imshow(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
